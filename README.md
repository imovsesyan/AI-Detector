# AI-Detector
The Armenian AI Text Detector is a machine learning system designed to automatically identify whether a given text was written by a human or generated by an AI model. It focuses specifically on Armenian-language content, where existing AI detectors perform poorly due to limited datasets and linguistic complexity.
ğŸ§  Armenian AI Text Detector

Reliable AI-generated text detection for the Armenian language

The Armenian AI Text Detector is a machine learning system designed to determine whether a given text was written by a human or generated by an AI model.
Unlike most existing detectors, this project focuses specifically on Armenian-language content, where commercial solutions perform poorly due to limited datasets and linguistic complexity.

This project was initiated to support Armenian governmental institutions, media organizations, and educational sectors in improving content authenticity and combating misinformation.

ğŸš€ Key Features

âœ… Detects AI-generated text in Armenian

âœ… Transformer-based classifier (RoBERTa / Gemma / LLaMA fine-tuned)

âœ… Custom Armenian dataset (human + AI)

âœ… Probability score output (AI vs Human)

âœ… Script and API usage

âœ… Deployment-ready inference pipeline

ğŸ—ï¸ Project Structure
ğŸ“¦ ai-detector
 â”£ ğŸ“ data
 â”£ ğŸ“ models
 â”£ ğŸ“ src
 â”ƒ â”£ data_preprocessing.py
 â”ƒ â”£ train.py
 â”ƒ â”£ inference.py
 â”ƒ â”— api.py
 â”£ README.md
 â”— requirements.txt

ğŸ“¥ Installation
git clone https://github.com/<username>/ai-detector.git
cd ai-detector
pip install -r requirements.txt

ğŸ§ª Quick Usage
Command-line inference
python src/inference.py --text "ÕÕ¥Ö€ Õ¿Õ¥Ö„Õ½Õ¿Õ¨ Õ¡ÕµÕ½Õ¿Õ¥Õ²"


Output example:

Prediction: AI-generated
Confidence: 0.82

Python usage
from src.inference import detect_text

text = "ÕˆÕ²Õ»Õ¸Ö‚ÕµÕ¶, Õ«Õ¶Õ¹ÕºÕ¥Õ½ Õ¥Õ½?"
result = detect_text(text)
print(result)

ğŸ”§ API (Optional)

Run a FastAPI server:

uvicorn src.api:app --reload


Example request:

POST /predict
{
  "text": "ÕÕ¥Ö„Õ½Õ¿Õ« Ö…Ö€Õ«Õ¶Õ¡Õ¯"
}


Response:

{
  "label": "human",
  "score": 0.73
}

ğŸ“Š Dataset

The dataset consists of:

Human-written Armenian texts

official documents

news articles

essays and academic writing

AI-generated texts

ChatGPT

Claude

Gemini

other LLMs

All samples were:

cleaned

normalized

labeled

balanced for training

ğŸ§  Model Training

Main steps:

Data preprocessing and tokenization

Fine-tuning a transformer model

Evaluation and benchmarking

Exporting the best-performing model

To train the model:

python src/train.py

ğŸ§¾ Performance
Metric	Score
Accuracy	XX%
F1 Score	XX%
Precision	XX%
Recall	XX%

âœ… Significantly outperforms generic English detectors on Armenian text

ğŸ¯ Purpose & Impact

This project aims to:

support governmental sectors in verifying document authenticity

assist media organizations in identifying AI-generated content

contribute to Armenian NLP research

build the first reliable Armenian AI detector

ğŸ›  Technologies Used

Python 3

PyTorch

Hugging Face Transformers

Scikit-learn

FastAPI (optional)

NumPy / pandas

Tokenizers

ğŸ“Œ Roadmap

 Improve dataset size and diversity

 Add support for dialects and informal Armenian

 Evaluate on education-sector texts

 Web interface / dashboard

 Public model release on Hugging Face

ğŸ¤ Contribution

Contributions are welcome!

If you would like to:

add data

improve the model

integrate deployment tools

please open an issue or submit a pull request.

ğŸ“œ License

MIT License
