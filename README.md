# Armenian AI Text Detector

The Armenian AI Text Detector is a machine learning system designed to determine whether a given text was written by a human or generated by an AI model. This project focuses specifically on Armenian-language content, where existing commercial AI detectors perform poorly due to limited datasets and linguistic characteristics of the Armenian language.

The project was developed to support Armenian governmental institutions, media organizations, and educational sectors in improving content authenticity and combating misinformation.

## Key Features

- Detects AI-generated text in Armenian
- Transformer-based classifier (RoBERTa / Gemma / LLaMA fine-tuned)
- Custom Armenian dataset (human and AI texts)
- Probability score output (AI vs Human)
- Script and API usage
- Deployment-ready inference pipeline

## Project Structure

ai-detector
├── data
├── models
├── src
│ ├── data_preprocessing.py
│ ├── train.py
│ ├── inference.py
│ └── api.py
├── README.md
└── requirements.txt

## Installation
git clone https://github.com/
<username>/ai-detector.git
cd ai-detector
pip install -r requirements.txt


## Quick Usage

### Command-line

python src/inference.py --text "Ձեր տեքստը այստեղ"

Prediction example:
Prediction: AI-generated
Confidence: 0.82


### Python

```python
from src.inference import detect_text

text = "Ողջույն, ինչպես ես?"
result = detect_text(text)
print(result)

POST /predict
{
  "text": "Տեքստի օրինակ"
}

{
  "label": "human",
  "score": 0.73
}
```
## Dataset

The dataset includes:

### Human-written Armenian texts:
- official documents
- news articles
- essays and academic writing

### AI-generated texts from:
- ChatGPT
- Claude
- Gemini
- other large language models

All samples were **cleaned, normalized, labeled, and balanced** for training.

## Model Training

The model training process consists of:

1. **Data preprocessing and tokenization**
2. **Fine-tuning a transformer model**
3. **Evaluation and benchmarking**
4. **Exporting the best-performing model**

To train the model:

```bash
python src/train.py
```
## Performance

Accuracy: **XX%**  
F1 Score: **XX%**  
Precision: **XX%**  
Recall: **XX%**

The model performs **significantly better than generic English AI detectors** on Armenian text.

## Purpose and Impact

This project aims to:

- support governmental sectors in verifying document authenticity
- assist media organizations in identifying AI-generated content
- contribute to Armenian NLP research
- build the first reliable Armenian AI detector

## Technologies Used

- Python 3
- PyTorch
- Hugging Face Transformers
- Scikit-learn
- FastAPI (optional)
- NumPy
- pandas
- Tokenizers

## Roadmap

- Improve dataset size and diversity
- Add support for dialects and informal Armenian
- Evaluate on education-sector texts
- Web interface / dashboard
- Public model release on Hugging Face

## Contribution

Contributions are welcome.  
To contribute, please open an issue or submit a pull request.

## License

MIT License



